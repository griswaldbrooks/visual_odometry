{"id":"visual_odometry-00n","title":"Update .clang-tidy to enforce snake_case for all types","description":"The .clang-tidy file currently enforces CamelCase for structs, classes, concepts, enums, type aliases, etc. This is wrong - we want snake_case everywhere. Update all *Case settings to lower_case. Also add ConceptSuffix: '_like' to enforce concept naming convention.","status":"closed","priority":1,"issue_type":"bug","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T17:22:53.43404411-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T17:25:04.955845815-05:00","closed_at":"2026-01-23T17:25:04.955845815-05:00","close_reason":"Closed"}
{"id":"visual_odometry-0bg","title":"Add DISK feature detector via ONNX","description":"Download DISK ONNX weights from LightGlue-ONNX releases. Create DiskDetector class that runs ONNX inference. Apache-2.0 licensed - preferred over SuperPoint for commercial use.","status":"closed","priority":2,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:08:42.217374027-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-20T19:44:57.036172909-05:00","closed_at":"2026-01-20T19:44:57.036172909-05:00","close_reason":"Breaking down into smaller Ralph-ready tasks","dependencies":[{"issue_id":"visual_odometry-0bg","depends_on_id":"visual_odometry-siw","type":"blocks","created_at":"2026-01-20T19:08:49.807811673-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-0ff","title":"Configure GitHub Actions CI workflow","description":"Create .github/workflows/ci.yml with build-and-test job (pixi setup, configure, build, test) and sanitizers job (ASan + UBSan with strict env vars). Reference: /home/griswald/picknik/chessBot2/.github/workflows/ci.yml","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:08:50.519993522-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T13:55:09.191671244-05:00","closed_at":"2026-01-12T13:55:09.191671244-05:00","close_reason":"Created .github/workflows/ci.yml with build-and-test and sanitizers jobs","dependencies":[{"issue_id":"visual_odometry-0ff","depends_on_id":"visual_odometry-dyt","type":"blocks","created_at":"2026-01-12T12:09:48.902880291-05:00","created_by":"Griswald Brooks"},{"issue_id":"visual_odometry-0ff","depends_on_id":"visual_odometry-odu","type":"blocks","created_at":"2026-01-12T12:09:48.976895062-05:00","created_by":"Griswald Brooks"},{"issue_id":"visual_odometry-0ff","depends_on_id":"visual_odometry-7o7","type":"blocks","created_at":"2026-01-12T12:09:49.057002309-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-0nc","title":"Enforce snake_case for all identifiers including types","description":"Update naming conventions to use snake_case everywhere, including struct/class names (e.g., motion_estimator_config instead of MotionEstimatorConfig). Configure clang-tidy and clang-format to enforce this. Update .clang-tidy readability-identifier-naming checks. This is a breaking change that will require renaming all types in the codebase.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T16:03:03.915223271-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T17:23:43.378624624-05:00","closed_at":"2026-01-23T17:23:43.378624624-05:00","close_reason":"Duplicate of visual_odometry-00n (fix clang-tidy) and visual_odometry-1rm (rename types)"}
{"id":"visual_odometry-0qj","title":"Create trajectory interpolation utility for time-aligned comparison","description":"Create a Python utility to interpolate trajectory poses at arbitrary timestamps.\n\nRequirements:\n- Load TUM format (timestamp tx ty tz qx qy qz qw)\n- Load KITTI format (3x4 matrices) - need to assign timestamps based on frame rate\n- Load trajectory.json format\n- Interpolate position (linear) and orientation (slerp) at any timestamp\n- Handle edge cases (query before/after trajectory bounds)\n\nAPI:\n```python\nclass TrajectoryInterpolator:\n    def __init__(self, timestamps: np.ndarray, poses: np.ndarray): ...\n    def interpolate(self, t: float) -\u003e Pose: ...\n    def interpolate_batch(self, timestamps: np.ndarray) -\u003e list[Pose]: ...\n\ndef load_trajectory(path: Path, format: str = 'auto') -\u003e TrajectoryInterpolator: ...\n```\n\nSUCCESS: Can interpolate poses at arbitrary timestamps with correct slerp for rotations.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T17:02:56.538683773-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T17:08:00.115114789-05:00","closed_at":"2026-01-25T17:08:00.115114789-05:00","close_reason":"Implemented trajectory_utils.py with TrajectoryInterpolator and loaders for TUM/KITTI/JSON"}
{"id":"visual_odometry-0s2","title":"Re-add MatchAnything matcher after ONNX export","description":"Once the MatchAnything ONNX export is complete (visual_odometry-6ri), re-implement the MatchAnythingMatcher using the ONNX Runtime like LightGlue. The previous Python subprocess implementation was removed due to being slow and fragile. The new implementation should follow the LightGlueImageMatcher pattern with OnnxSession.","status":"open","priority":3,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T15:54:05.693544023-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T15:54:05.693544023-05:00","dependencies":[{"issue_id":"visual_odometry-0s2","depends_on_id":"visual_odometry-6ri","type":"blocks","created_at":"2026-01-23T15:54:10.746456543-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-0w2","title":"Fix camelCase local variables in test files (9 instances)","status":"closed","priority":3,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T18:16:38.383677961-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T18:37:29.168015408-05:00","closed_at":"2026-01-12T18:37:29.168015408-05:00","close_reason":"Test files already use snake_case for local variables. Only camelCase found was OpenCV API members (queryIdx, trainIdx) which are external."}
{"id":"visual_odometry-1cy","title":"Switch from Catch2 to gtest/gmock","description":"Replace Catch2 with googletest in pixi.toml, CMakeLists.txt, and tests. ~15 min","status":"closed","priority":0,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T15:57:32.189964285-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T15:59:17.360685577-05:00","closed_at":"2026-01-12T15:59:17.360685577-05:00","close_reason":"Switched from Catch2 to gtest/gmock. Build and tests pass."}
{"id":"visual_odometry-1gw","title":"Fix performance-no-automatic-move violations","description":"Fix cases where const local variables prevent automatic move on return. Remove const from local variables that are returned to enable move semantics. Check image_loader.cpp load_image function.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T20:31:12.770386664-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-24T01:38:01.674261958-05:00","closed_at":"2026-01-24T01:38:01.674261958-05:00","close_reason":"Fixed in commit c5f23e3","dependencies":[{"issue_id":"visual_odometry-1gw","depends_on_id":"visual_odometry-96q","type":"blocks","created_at":"2026-01-23T20:31:19.612762296-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-1hi","title":"Implement feature matching module","description":"Implement feature matching between consecutive frames using BFMatcher or FLANN with ratio test","status":"closed","priority":2,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:01:26.55303236-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T15:49:02.660151481-05:00","closed_at":"2026-01-12T15:49:02.660151481-05:00","close_reason":"Superseded by smaller incremental tasks","dependencies":[{"issue_id":"visual_odometry-1hi","depends_on_id":"visual_odometry-mr0","type":"blocks","created_at":"2026-01-12T12:02:13.479698052-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-1jc","title":"Wire up VO pipeline in main.cpp","description":"Connect the existing components to create an end-to-end visual odometry pipeline:\n- Load images from KITTI dataset using ImageLoader\n- Detect features using FeatureDetector\n- Match features between consecutive frames using FeatureMatcher\n- Estimate motion using MotionEstimator\n- Accumulate poses in Trajectory\n- Output trajectory JSON for visualization\n\nThe components exist but main.cpp is currently a placeholder.","status":"closed","priority":1,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-13T16:36:05.091997606-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-13T19:31:29.22888589-05:00","closed_at":"2026-01-13T19:31:29.22888589-05:00","close_reason":"Full VO pipeline wired up and tested end-to-end","dependencies":[{"issue_id":"visual_odometry-1jc","depends_on_id":"visual_odometry-lyl","type":"blocks","created_at":"2026-01-13T16:57:15.647879109-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-1rm","title":"Rename all PascalCase types to snake_case","description":"Rename all remaining PascalCase types to snake_case: Pose -\u003e pose, DetectionResult -\u003e detection_result, FeatureDetectorConfig -\u003e feature_detector_config, MatchResult -\u003e match_result, FeatureMatcherConfig -\u003e feature_matcher_config, CameraIntrinsics -\u003e camera_intrinsics, MotionEstimatorConfig -\u003e motion_estimator_config, MotionEstimate -\u003e motion_estimate. Update all usages.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T17:22:53.574067735-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T17:31:33.538202906-05:00","closed_at":"2026-01-23T17:31:33.538202906-05:00","close_reason":"Closed","dependencies":[{"issue_id":"visual_odometry-1rm","depends_on_id":"visual_odometry-00n","type":"blocks","created_at":"2026-01-23T17:23:14.645896078-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-1tx","title":"Add unit tests for trajectory interpolation and error metrics","description":"Write comprehensive unit tests for the trajectory comparison utilities.\n\nTests for interpolation:\n- Interpolate at exact timestamp returns exact pose\n- Interpolate between timestamps returns correct linear interp (position)\n- Interpolate between timestamps returns correct slerp (orientation)\n- Edge case: query before first timestamp\n- Edge case: query after last timestamp\n- Edge case: single-pose trajectory\n\nTests for error metrics:\n- Identical trajectories have zero error\n- Known offset trajectory has expected error\n- Different sample rates handled correctly\n- Per-axis errors sum correctly to total error\n\nUse pytest with parametrized tests where appropriate.\n\nSUCCESS: All tests pass, \u003e90% coverage on new code.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T17:02:56.982044452-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T17:08:00.237597396-05:00","closed_at":"2026-01-25T17:08:00.237597396-05:00","close_reason":"Implemented unit tests in scripts/tests/test_trajectory_utils.py - all 14 tests pass","dependencies":[{"issue_id":"visual_odometry-1tx","depends_on_id":"visual_odometry-0qj","type":"blocks","created_at":"2026-01-25T17:03:01.88626977-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-1u3","title":"Implement motion estimation","description":"Compute Essential matrix from matched features and recover camera rotation/translation using RANSAC","status":"closed","priority":2,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:01:34.334473693-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T15:49:02.666632538-05:00","closed_at":"2026-01-12T15:49:02.666632538-05:00","close_reason":"Superseded by smaller incremental tasks","dependencies":[{"issue_id":"visual_odometry-1u3","depends_on_id":"visual_odometry-1hi","type":"blocks","created_at":"2026-01-12T12:02:13.653256631-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-1x2","title":"Create main project README with visualization workflow","description":"Create a comprehensive README.md for the project root.\n\nSections to include:\n1. **Overview**: What is this project (visual odometry pipeline)\n2. **Quick Start**: Build and run in 3 commands\n3. **Installation**: pixi setup\n4. **Downloading Test Data**: \n   - TUM RGB-D dataset (./scripts/download_tum.sh)\n   - KITTI (link to manual download)\n5. **Running Visual Odometry**:\n   - Basic usage with ORB matcher\n   - Using LightGlue matcher\n6. **Visualization Tools**:\n   - plot_trajectory.py - single trajectory with images\n   - compare_trajectories.py - compare two trajectories\n   - visualize_trajectory.py - 3D viser view\n   - generate_test_trajectory.py - synthetic test data\n7. **Development**: Build, test, format, lint commands\n8. **Project Structure**: Key directories and files\n\nKeep it concise but complete. Include actual command examples that work.\n\nSUCCESS: New user can go from clone to visualization in under 10 minutes.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T17:50:29.124243045-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T17:51:42.870327087-05:00","closed_at":"2026-01-25T17:51:42.870327087-05:00","close_reason":"Created comprehensive README.md with quick start, data download, VO usage, visualization tools, and development guide"}
{"id":"visual_odometry-21b","title":"Create Python module and test with viser","description":"Final integration:\n- Create visual_odometry Python module entry point\n- Add __init__.py with clean API\n- Test importing from Python\n- Create example script showing live viser visualization\n- Verify cv::Mat \u003c-\u003e numpy works correctly","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-19T18:47:17.393712685-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-19T19:42:54.672120603-05:00","closed_at":"2026-01-19T19:42:54.672120603-05:00","close_reason":"Python module created with __init__.py and live_visualization.py example","dependencies":[{"issue_id":"visual_odometry-21b","depends_on_id":"visual_odometry-a3r","type":"blocks","created_at":"2026-01-19T18:50:54.627542123-05:00","created_by":"Griswald Brooks"},{"issue_id":"visual_odometry-21b","depends_on_id":"visual_odometry-ftq","type":"blocks","created_at":"2026-01-19T18:50:54.678682509-05:00","created_by":"Griswald Brooks"},{"issue_id":"visual_odometry-21b","depends_on_id":"visual_odometry-l5t","type":"blocks","created_at":"2026-01-19T18:50:54.722688099-05:00","created_by":"Griswald Brooks"},{"issue_id":"visual_odometry-21b","depends_on_id":"visual_odometry-6e5","type":"blocks","created_at":"2026-01-19T18:50:54.774093209-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-227","title":"Initialize ImageLoader in main.cpp","description":"Use ImageLoader::create() to initialize the image loader.\nReport number of images found.\nHandle errors gracefully.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-13T16:57:07.890111007-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-13T18:43:04.504718289-05:00","closed_at":"2026-01-13T18:43:04.504718289-05:00","close_reason":"ImageLoader initialization implemented with error handling and image count reporting","dependencies":[{"issue_id":"visual_odometry-227","depends_on_id":"visual_odometry-acx","type":"blocks","created_at":"2026-01-13T16:57:15.367464993-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-22r","title":"Design feature matcher abstraction for multiple backends","description":"Create an abstraction layer for feature matching that supports multiple backends:\n- ORB (current OpenCV implementation)\n- MatchAnything (learned matcher from ZJU)\n\nDesign decisions needed:\n1. Runtime vs compile-time selection (or both?)\n2. Interface design - both matchers have different APIs\n3. ORB: detect + match separately\n4. MatchAnything: end-to-end matching on image pairs\n\nConsider using std::variant or virtual interface.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-13T16:36:05.282041555-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-13T20:04:46.97695053-05:00","closed_at":"2026-01-13T20:04:46.97695053-05:00","close_reason":"Implemented ImageMatcher abstraction with virtual interface, OrbImageMatcher, factory function, and CLI --matcher flag"}
{"id":"visual_odometry-28p","title":"Add axis swap controls to compare_trajectories.py","description":"Add UI controls to swap/remap axes between ground truth and estimated trajectories. Different coordinate conventions (e.g., Y-up vs Z-up, right-handed vs left-handed) mean axes may not align between GT and EST. Need dropdowns or controls to remap X/Y/Z for the estimated trajectory.","status":"open","priority":2,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T19:22:03.8509182-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T19:22:03.8509182-05:00"}
{"id":"visual_odometry-2ew","title":"Refactor lightglue_matcher to satisfy matcher concept","description":"Refactor LightGlueImageMatcher to lightglue_matcher (snake_case). Remove inheritance from ImageMatcher base class. Ensure it satisfies the matcher concept. Keep ONNX session ownership (RAII pattern).","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T16:45:50.56486563-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T16:49:58.191281694-05:00","closed_at":"2026-01-23T16:49:58.191281694-05:00","close_reason":"Closed","dependencies":[{"issue_id":"visual_odometry-2ew","depends_on_id":"visual_odometry-5rh","type":"blocks","created_at":"2026-01-23T16:45:59.900910553-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-386","title":"Add sample dataset and demo","description":"Include sample image sequence or instructions for downloading KITTI/TUM dataset for testing","status":"closed","priority":3,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:01:42.357625572-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T15:49:02.689285428-05:00","closed_at":"2026-01-12T15:49:02.689285428-05:00","close_reason":"Superseded by smaller incremental tasks"}
{"id":"visual_odometry-3kk","title":"Export MatchAnything to ONNX for C++ inference","description":"Export the MatchAnything (zju-community/matchanything_eloftr) HuggingFace model to ONNX format. This enables pure C++ inference without Python runtime dependency. Steps: 1) Load model with transformers, 2) Export with torch.onnx.export(), 3) Validate output matches PyTorch version, 4) Optimize with onnx-simplifier if needed.","status":"closed","priority":1,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T18:38:54.975154998-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-20T19:08:56.358256589-05:00","closed_at":"2026-01-20T19:08:56.358256589-05:00","close_reason":"Superseded: switching to LightGlue/DISK via ONNX instead of MatchAnything subprocess. See visual_odometry-siw and visual_odometry-utm."}
{"id":"visual_odometry-3l0","title":"Match ORB features between two images","description":"Use BFMatcher to match ORB descriptors between frame0 and frame1. Apply ratio test. Visualize matches with drawMatches(). ~30 min","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T15:49:20.947488864-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T16:34:18.468886041-05:00","closed_at":"2026-01-12T16:34:18.468886041-05:00","close_reason":"Created FeatureMatcher with Lowe's ratio test. All 5 new tests pass (19 total).","dependencies":[{"issue_id":"visual_odometry-3l0","depends_on_id":"visual_odometry-m0d","type":"blocks","created_at":"2026-01-12T15:49:47.614230666-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-3mj","title":"Fix viser API compatibility in visualize_trajectory.py","description":"The ViserServer API has changed - .port attribute no longer exists.\n\nError:\nAttributeError: 'ViserServer' object has no attribute 'port'\n\nFile: scripts/visualize_trajectory.py:92\n\nNeed to update to use current viser API for getting server URL/port.","status":"closed","priority":1,"issue_type":"bug","owner":"griswald.brooks@gmail.com","created_at":"2026-01-13T11:36:21.076698833-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-13T15:12:45.397648972-05:00","closed_at":"2026-01-13T15:12:45.397648972-05:00","close_reason":"Fixed viser API: changed server.port to server.get_port()"}
{"id":"visual_odometry-3ts","title":"Add OnnxSession unit test","description":"Create tests/test_onnx_session.cpp. Test loading a simple ONNX model (can use a minimal test model or skip if no model available). Test error handling for missing file. SUCCESS: pixi run test passes with new test.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:45:08.494641572-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-21T10:32:49.441021824-05:00","closed_at":"2026-01-21T10:32:49.441021824-05:00","close_reason":"Added test_onnx_session.cpp with 7 tests. All pass. Added LSAN suppression for onnxruntime leaks in CMakePresets.json.","dependencies":[{"issue_id":"visual_odometry-3ts","depends_on_id":"visual_odometry-c8i","type":"blocks","created_at":"2026-01-20T19:45:56.896364305-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-3yd","title":"Add Google Benchmark microbenchmarks for MotionEstimator","description":"Create microbenchmarks for MotionEstimator using Google Benchmark. Benchmark: estimate() with various match counts. Measure RANSAC iteration time and essential matrix decomposition.","status":"open","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T15:20:18.856519096-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T15:20:29.5640636-05:00","dependencies":[{"issue_id":"visual_odometry-3yd","depends_on_id":"visual_odometry-ymv","type":"blocks","created_at":"2026-01-23T15:20:33.786742554-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-485","title":"VO should output timestamps with each pose","description":"trajectory.json only contains rotation/translation but no timestamps. The VO should output the timestamp from the input image with each pose. This is needed for proper trajectory comparison with ground truth. Currently compare_trajectories.py has to guess FPS which is unreliable.","status":"closed","priority":2,"issue_type":"bug","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T19:16:31.436944623-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T19:19:30.339780702-05:00","closed_at":"2026-01-25T19:19:30.339780702-05:00","close_reason":"Replacing with more specific bead"}
{"id":"visual_odometry-4it","title":"Use string_view for non-owning string parameters (3 instances)","status":"closed","priority":3,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T18:16:37.039155921-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T18:31:28.250554404-05:00","closed_at":"2026-01-12T18:31:28.250554404-05:00","close_reason":"Changed std::string const\u0026 to std::string_view in ImageLoader::create and CameraIntrinsics::load_from_yaml"}
{"id":"visual_odometry-4kg","title":"Add SuperPoint feature detector via ONNX","description":"Download SuperPoint ONNX weights from LightGlue-ONNX releases. Create SuperPointDetector class that runs ONNX inference. Handles image preprocessing (grayscale, normalize) and output parsing (keypoints, descriptors). Note: SuperPoint weights are non-commercial license.","status":"closed","priority":2,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:08:42.034757721-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-20T19:44:57.03042072-05:00","closed_at":"2026-01-20T19:44:57.03042072-05:00","close_reason":"Breaking down into smaller Ralph-ready tasks","dependencies":[{"issue_id":"visual_odometry-4kg","depends_on_id":"visual_odometry-siw","type":"blocks","created_at":"2026-01-20T19:08:49.760143841-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-4vw","title":"Remove const_cast usage in onnx_session.cpp","description":"Investigate and remove the const_cast in onnx_session.cpp. const_cast to remove const is a code smell and there's always an alternative in greenfield code. May need to redesign the API or find a different approach for ONNX Runtime interop.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T20:31:12.632844666-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-24T01:38:01.671774378-05:00","closed_at":"2026-01-24T01:38:01.671774378-05:00","close_reason":"Fixed in commit c5f23e3","dependencies":[{"issue_id":"visual_odometry-4vw","depends_on_id":"visual_odometry-96q","type":"blocks","created_at":"2026-01-23T20:31:19.557169404-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-55q","title":"Add reset button to undo auto-alignment","description":"Add a 'Reset' button next to the Auto-align button that resets scale and offsets to default values (scale=1.0, offset_x=0, offset_y=0, offset_z=0). This allows users to quickly undo auto-alignment and return to the original unaligned view.","status":"open","priority":3,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T19:46:45.340546333-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T19:46:45.340546333-05:00"}
{"id":"visual_odometry-58s","title":"Process image sequence and accumulate trajectory","description":"Loop over N frames, chain relative transforms, accumulate full trajectory. Store as list of poses. ~30 min","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T15:49:33.759954603-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T19:38:36.57744483-05:00","closed_at":"2026-01-12T19:38:36.57744483-05:00","close_reason":"Added Trajectory class with Pose struct for accumulating camera poses. Implemented compose for chaining transforms.","dependencies":[{"issue_id":"visual_odometry-58s","depends_on_id":"visual_odometry-m46","type":"blocks","created_at":"2026-01-12T15:49:50.102351654-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-5f4","title":"Rename camelCase functions to snake_case (13 functions)","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T18:16:23.1887107-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T18:23:21.785563732-05:00","closed_at":"2026-01-12T18:23:21.785563732-05:00","close_reason":"Refactored to new coding standards: east const, snake_case, [[nodiscard]], trailing returns, tl::expected for error handling. All tests pass."}
{"id":"visual_odometry-5g3","title":"Integrate MatchAnything feature matcher","description":"Integrate MatchAnything (zju3dv) as an alternative feature matcher.\n\nReferences:\n- GitHub: https://github.com/zju3dv/MatchAnything\n- HuggingFace weights: zju-community/matchanything_eloftr\n- Based on ELoFTR architecture\n\nTechnical considerations:\n- Requires PyTorch (libtorch C++ API or Python interop)\n- 40ms per 640x480 image pair on RTX 3090\n- Weights need to be downloaded from HuggingFace\n\nOptions for integration:\n1. libtorch (PyTorch C++ frontend)\n2. pybind11 Python interop\n3. Subprocess with IPC","status":"closed","priority":2,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-13T16:36:05.47634097-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-13T21:41:09.678095094-05:00","closed_at":"2026-01-13T21:41:09.678095094-05:00","close_reason":"Implemented MatchAnythingMatcher via Python subprocess. Requires: pip install transformers torch","dependencies":[{"issue_id":"visual_odometry-5g3","depends_on_id":"visual_odometry-22r","type":"blocks","created_at":"2026-01-13T16:36:11.039953539-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-5h8","title":"Fix misc-include-cleaner violations - add direct includes","description":"Fix all misc-include-cleaner violations by adding direct includes for types used. Don't rely on transitive includes. Examples: include \u003copencv2/core/mat.hpp\u003e for cv::Mat, include \u003cvector\u003e for std::vector, include \u003cspan\u003e for std::span, etc.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T20:31:12.144192879-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-24T01:38:01.663707755-05:00","closed_at":"2026-01-24T01:38:01.663707755-05:00","close_reason":"Fixed in commit c5f23e3","dependencies":[{"issue_id":"visual_odometry-5h8","depends_on_id":"visual_odometry-96q","type":"blocks","created_at":"2026-01-23T20:31:19.348036991-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-5hk","title":"Add accuracy metrics to benchmark","description":"Extend benchmark to compute: match count, inlier ratio (after RANSAC), repeatability if ground truth available. Store in JSON output alongside timing. SUCCESS: Benchmark JSON includes accuracy fields.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:45:34.341288513-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T13:55:10.120647771-05:00","closed_at":"2026-01-23T13:55:10.120647771-05:00","close_reason":"Closed","dependencies":[{"issue_id":"visual_odometry-5hk","depends_on_id":"visual_odometry-xhj","type":"blocks","created_at":"2026-01-20T19:45:58.129023303-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-5nl","title":"Implement LightGlue image preprocessing","description":"In LightGlueImageMatcher, implement preprocess() that converts cv::Mat to ONNX tensor. Steps: convert to float32, normalize to [0,1], resize to multiple of 16, create Ort::Value. Reference LightGlue-OnnxRunner for exact preprocessing. SUCCESS: preprocess() compiles and returns valid Ort::Value.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:45:25.399147353-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-21T11:26:46.762044544-05:00","closed_at":"2026-01-21T11:26:46.762044544-05:00","close_reason":"Implemented preprocess_image_for_lightglue() function that converts cv::Mat to ONNX tensor format: grayscale-\u003eRGB, normalize [0,1], HWC-\u003eCHW, returns {float_vector, shape}. Compiles successfully.","dependencies":[{"issue_id":"visual_odometry-5nl","depends_on_id":"visual_odometry-5qo","type":"blocks","created_at":"2026-01-20T19:45:57.150034915-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-5qo","title":"Create LightGlueImageMatcher class skeleton","description":"Create LightGlueImageMatcher class in image_matcher.hpp inheriting from ImageMatcher. Constructor takes model_path. Stub match_images() to return empty MatchResult. Add 'lightglue' case to create_matcher() factory. SUCCESS: pixi run build passes, create_matcher('lightglue') returns non-null.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:45:25.244685045-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-21T10:48:21.211614079-05:00","closed_at":"2026-01-21T10:48:21.211614079-05:00","close_reason":"Added LightGlueImageMatcher class skeleton with constructor, destructor, move operations, and stub match_images(). Added 'lightglue' case to create_matcher(). Build passes, tests pass.","dependencies":[{"issue_id":"visual_odometry-5qo","depends_on_id":"visual_odometry-c8i","type":"blocks","created_at":"2026-01-20T19:45:57.016969334-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-5rh","title":"Define matcher concept for image matching interface","description":"Create a C++20 concept that defines the interface for image matchers. The concept should require: match_images(img1, img2) -\u003e match_result, and name() -\u003e string_view. This will be used to constrain types in the std::variant and provide compile-time interface checking.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T16:45:50.288650745-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T16:47:34.502800463-05:00","closed_at":"2026-01-23T16:47:34.502800463-05:00","close_reason":"Closed"}
{"id":"visual_odometry-5se","title":"Remove ImageMatcher abstract base class","description":"Delete the ImageMatcher abstract base class after all call sites are updated to use std::variant + std::visit. This removes virtual dispatch overhead entirely.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T16:45:50.971284267-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T16:55:16.621050882-05:00","closed_at":"2026-01-23T16:55:16.621050882-05:00","close_reason":"Closed","dependencies":[{"issue_id":"visual_odometry-5se","depends_on_id":"visual_odometry-eqb","type":"blocks","created_at":"2026-01-23T16:46:00.376529298-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-5w6","title":"Create Python viser visualization script","description":"Python script using viser to load trajectory JSON and display 3D camera path. Add coordinate frames, trajectory line. ~30 min","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T15:55:27.647524361-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T19:58:12.642187813-05:00","closed_at":"2026-01-12T19:58:12.642187813-05:00","close_reason":"Script already existed. Fixed JSON format compatibility to handle C++ output format {'poses': [...]}. Verified with pixi run -e viz viz-trajectory.","dependencies":[{"issue_id":"visual_odometry-5w6","depends_on_id":"visual_odometry-i0g","type":"blocks","created_at":"2026-01-12T15:55:39.353439979-05:00","created_by":"Griswald Brooks"},{"issue_id":"visual_odometry-5w6","depends_on_id":"visual_odometry-djp","type":"blocks","created_at":"2026-01-12T15:56:08.356005421-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-5xh","title":"VO should use input image timestamps for pose output","description":"The VO algorithm needs to:\n1. Accept timestamps with input images (from rgb.txt or image filenames in TUM format)\n2. Associate each pose estimate with the timestamp of the image it was computed from\n3. Output timestamps alongside poses in trajectory.json\n\nCurrently trajectory.json only has rotation/translation with no timestamps, making it impossible to accurately align with ground truth for evaluation. The input data (e.g., TUM rgb.txt) already has timestamps - they just need to flow through the pipeline.","status":"open","priority":2,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T19:19:30.511083239-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T19:19:30.511083239-05:00"}
{"id":"visual_odometry-60h","title":"Rename matcher concept to matcher_like","description":"Rename the 'matcher' concept to 'matcher_like' following the naming convention that concepts should be named \u003cthing\u003e_like. Update all usages in image_matcher.hpp, main.cpp, benchmarks, etc.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T17:22:53.742849987-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T17:26:25.613150544-05:00","closed_at":"2026-01-23T17:26:25.613150544-05:00","close_reason":"Closed","dependencies":[{"issue_id":"visual_odometry-60h","depends_on_id":"visual_odometry-00n","type":"blocks","created_at":"2026-01-23T17:23:14.733805032-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-6bl","title":"Create trajectory comparison visualization with plotly in viser","description":"Create visualization tool that shows trajectory comparison with time-series plots.\n\nPlots to show (using plotly embedded in viser):\n1. **X vs Time** - ground truth and estimated overlaid\n2. **Y vs Time** - ground truth and estimated overlaid  \n3. **Z vs Time** - ground truth and estimated overlaid\n4. **Error vs Time** - per-axis and total error over time\n5. **3D trajectory** - existing viser visualization\n\nFeatures:\n- Plotly plots embedded in viser GUI panel\n- Interactive zoom/pan on time series\n- Highlight corresponding point in 3D view when hovering time series\n- Show error statistics in panel\n\nUsage:\n```bash\npython scripts/compare_trajectories.py \\\n    --estimated trajectory.json \\\n    --ground-truth data/tum/.../groundtruth.txt \\\n    --estimated-fps 30\n```\n\nSUCCESS: Can visualize X/Y/Z vs time plots alongside 3D trajectory in viser.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T17:02:56.837742796-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T17:08:00.289212319-05:00","closed_at":"2026-01-25T17:08:00.289212319-05:00","close_reason":"Implemented compare_trajectories.py with viser 3D view and plotly time-series plots","dependencies":[{"issue_id":"visual_odometry-6bl","depends_on_id":"visual_odometry-xo5","type":"blocks","created_at":"2026-01-25T17:03:01.806394578-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-6e5","title":"Bind Trajectory and Pose classes","description":"Create nanobind bindings for:\n- Pose struct (rotation, translation as numpy arrays)\n- Pose.identity(), Pose.compose(motion)\n- Trajectory class\n- add_motion(motion) -\u003e bool\n- poses() -\u003e list of Pose\n- current_pose(), size(), empty(), reset()\n- to_json() -\u003e str","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-19T18:47:16.881411877-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-19T19:27:50.591880222-05:00","closed_at":"2026-01-19T19:27:50.591880222-05:00","close_reason":"Pose and Trajectory bindings complete with indexing and JSON support","dependencies":[{"issue_id":"visual_odometry-6e5","depends_on_id":"visual_odometry-l1z","type":"blocks","created_at":"2026-01-19T18:50:54.573136877-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-6hf","title":"Load KITTI ground truth and compare trajectories","description":"Add ground truth poses to visualization. Show estimated vs GT trajectory in viser. Calculate ATE if time permits. ~30 min","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T15:49:35.287030615-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T19:59:41.210421462-05:00","closed_at":"2026-01-12T19:59:41.210421462-05:00","close_reason":"Added compute_ate() function for Absolute Trajectory Error metrics (RMSE, mean, median, std, min, max). GT visualization was already implemented.","dependencies":[{"issue_id":"visual_odometry-6hf","depends_on_id":"visual_odometry-58s","type":"blocks","created_at":"2026-01-12T15:49:51.004071192-05:00","created_by":"Griswald Brooks"},{"issue_id":"visual_odometry-6hf","depends_on_id":"visual_odometry-5w6","type":"blocks","created_at":"2026-01-12T15:55:40.002883566-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-6kq","title":"Create activation script for compiler setup","description":"Create activation.sh that sets CC=clang and CXX=clang++ from CONDA_PREFIX/bin for pixi environment activation. Reference: /home/griswald/picknik/chessBot2/activation.sh","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:09:27.588649337-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T13:30:18.789896849-05:00","closed_at":"2026-01-12T13:30:18.789896849-05:00","close_reason":"Created activation.sh as part of pixi setup","dependencies":[{"issue_id":"visual_odometry-6kq","depends_on_id":"visual_odometry-dyt","type":"blocks","created_at":"2026-01-12T12:09:40.595690609-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-6ok","title":"Configure clang-format code style","description":"Create .clang-format with Google-based style, C++20, 4-space indent, 100-col line length, left-aligned pointers, namespace formatting, include sorting, and brace insertion. Reference: /home/griswald/picknik/chessBot2/.clang-format","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:09:02.644702252-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T13:45:40.407279246-05:00","closed_at":"2026-01-12T13:45:40.407279246-05:00","close_reason":"Created .clang-format based on chessBot2 config"}
{"id":"visual_odometry-6ri","title":"[Research] Export MatchAnything to ONNX","description":"Investigate exporting MatchAnything (zju-community/matchanything_eloftr) to ONNX. Uses ELoFTR architecture with special training for cross-modality matching. May be able to adapt loftr2onnx converter. Low priority unless cross-modality matching needed.","status":"open","priority":3,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:08:42.655345807-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-20T19:08:42.655345807-05:00"}
{"id":"visual_odometry-7o7","title":"Set up Catch2 testing framework","description":"Add Catch2 v3+ dependency, create tests/CMakeLists.txt with test executable, link against project library, enable catch_discover_tests(). Reference: /home/griswald/picknik/chessBot2/tests/CMakeLists.txt","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:09:03.004729644-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T13:42:34.316768334-05:00","closed_at":"2026-01-12T13:42:34.316768334-05:00","close_reason":"Configured in CMakeLists.txt as part of CMake setup","dependencies":[{"issue_id":"visual_odometry-7o7","depends_on_id":"visual_odometry-odu","type":"blocks","created_at":"2026-01-12T12:09:48.234072895-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-7te","title":"Add feature matcher benchmark suite","description":"Create benchmark infrastructure to compare matchers (ORB, LightGlue, etc.) on accuracy (AUC, inlier ratio) and speed (ms/pair). Use standard datasets like HPatches or custom VO sequences. Output markdown report with tables and plots.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:08:41.760030839-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-20T19:44:57.180600112-05:00","closed_at":"2026-01-20T19:44:57.180600112-05:00","close_reason":"Breaking down into smaller Ralph-ready tasks","dependencies":[{"issue_id":"visual_odometry-7te","depends_on_id":"visual_odometry-utm","type":"blocks","created_at":"2026-01-20T19:08:49.907525826-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-8lq","title":"Configure .gitattributes with LFS support","description":"Set up Git LFS for binary data (images, calibration files, datasets). Configure proper diff handling for C++, CMake, and markdown files. Reference: /home/griswald/picknik/chessBot2/.gitattributes","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:09:27.375981362-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T13:49:37.797468944-05:00","closed_at":"2026-01-12T13:49:37.797468944-05:00","close_reason":"Updated .gitattributes with LFS support for images, video, point clouds, and calibration data"}
{"id":"visual_odometry-8q4","title":"Add constexpr where applicable","status":"closed","priority":3,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T18:16:37.986299072-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T18:34:31.452005906-05:00","closed_at":"2026-01-12T18:34:31.452005906-05:00","close_reason":"Added constexpr constants: default_max_features, default_ratio_threshold, default_ransac_threshold, default_ransac_confidence, min_motion_inliers, min_essential_points"}
{"id":"visual_odometry-962","title":"Add nanobind Python bindings for live visualization","description":"Create Python bindings using nanobind to enable live visualization of VO pipeline with viser.\n\nThis is the parent epic for the nanobind integration work.\n\nResult: Python module 'visual_odometry' that can be imported and used with viser for live trajectory visualization.","status":"closed","priority":1,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-19T18:46:58.474861893-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-19T19:42:54.717876986-05:00","closed_at":"2026-01-19T19:42:54.717876986-05:00","close_reason":"All nanobind binding tasks complete - module imports and works","dependencies":[{"issue_id":"visual_odometry-962","depends_on_id":"visual_odometry-21b","type":"blocks","created_at":"2026-01-19T18:50:54.821686114-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-96q","title":"Disable pragma-once and uppercase-literal-suffix clang-tidy checks","description":"Update .clang-tidy to disable checks we don't want: -portability-avoid-pragma-once (pragma once is fine), -readability-uppercase-literal-suffix (lowercase f is fine). Keep WarningsAsErrors: '*' for everything else.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T20:31:11.975056174-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-24T01:38:01.661178071-05:00","closed_at":"2026-01-24T01:38:01.661178071-05:00","close_reason":"Fixed in commit c5f23e3"}
{"id":"visual_odometry-9b5","title":"Rename remaining PascalCase classes to snake_case","description":"Rename remaining classes that violate snake_case naming: OnnxSession -\u003e onnx_session, VisualOdometry -\u003e visual_odometry, ImageLoader -\u003e image_loader. Also convert from class to struct. Update all usages.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T20:31:12.292849596-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-24T01:38:01.666319711-05:00","closed_at":"2026-01-24T01:38:01.666319711-05:00","close_reason":"Fixed in commit c5f23e3","dependencies":[{"issue_id":"visual_odometry-9b5","depends_on_id":"visual_odometry-96q","type":"blocks","created_at":"2026-01-23T20:31:19.427486799-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-9vf","title":"Add Google Benchmark microbenchmarks for FeatureDetector","description":"Create microbenchmarks for FeatureDetector using Google Benchmark. Benchmark: detect_features() with various image sizes and max_features settings. Measure ORB creation overhead vs detection time. Compare with class-based API.","status":"open","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T15:20:18.589192072-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T15:20:29.308777289-05:00","dependencies":[{"issue_id":"visual_odometry-9vf","depends_on_id":"visual_odometry-ymv","type":"blocks","created_at":"2026-01-23T15:20:33.646064248-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-9yl","title":"Download LightGlue ONNX weights","description":"Download disk_lightglue_fused.onnx from https://github.com/fabio-sim/LightGlue-ONNX/releases/download/v1.0.0/disk_lightglue_fused.onnx to models/ directory. Add models/ to .gitignore if not present. Create scripts/download_models.sh for reproducibility. SUCCESS: models/disk_lightglue_fused.onnx exists and is ~50MB.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:45:25.063159851-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-21T09:58:13.287573084-05:00","closed_at":"2026-01-21T09:58:13.287573084-05:00","close_reason":"Downloaded disk_lightglue_fused.onnx (44MB) to models/ directory"}
{"id":"visual_odometry-a39","title":"Create simple trajectory plotter (X/Y/Z vs time) for single trajectory","description":"Create a simple Python script that takes a single trajectory file and plots X, Y, Z vs time using plotly.\n\nShould support:\n- trajectory.json format (C++ VO output)\n- TUM ground truth format\n- KITTI ground truth format (auto-detect)\n\nUsage:\n```bash\npython scripts/plot_trajectory.py trajectory.json\npython scripts/plot_trajectory.py data/tum/.../groundtruth.txt\npython scripts/plot_trajectory.py /tmp/circle.txt\n```\n\nOutput:\n- Opens browser with 3 plotly subplots: X vs time, Y vs time, Z vs time\n- Interactive zoom/pan\n- Shows timestamps on x-axis\n\nThis is simpler than compare_trajectories.py - just visualize ONE trajectory at a time to verify it looks correct before doing comparisons.\n\nSUCCESS: Can plot any trajectory file and see X/Y/Z components over time.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T17:17:05.559809461-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T17:17:48.030820524-05:00","closed_at":"2026-01-25T17:17:48.030820524-05:00","close_reason":"Implemented plot_trajectory.py - simple X/Y/Z vs time plotly visualization"}
{"id":"visual_odometry-a3r","title":"Bind ImageLoader class","description":"Create nanobind bindings for ImageLoader:\n- create(path) -\u003e ImageLoader (handle expected\u003c\u003e error)\n- load_image(index) -\u003e numpy array\n- load_image_pair(index) -\u003e tuple of numpy arrays\n- next_pair() -\u003e tuple of numpy arrays\n- has_next(), reset(), size()\n\nConvert tl::expected errors to Python exceptions.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-19T18:47:15.370175938-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-19T19:11:56.550317454-05:00","closed_at":"2026-01-19T19:11:56.550317454-05:00","close_reason":"ImageLoader bindings complete with iteration support","dependencies":[{"issue_id":"visual_odometry-a3r","depends_on_id":"visual_odometry-l1z","type":"blocks","created_at":"2026-01-19T18:50:54.426586807-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-acx","title":"Add CLI argument parsing to main.cpp","description":"Add command-line argument parsing for:\n- --images: Path to image directory (required)\n- --camera: Path to camera intrinsics YAML (default: data/kitti/camera.yaml)\n- --output: Path for trajectory JSON output (default: trajectory.json)\n- --max-frames: Maximum frames to process (optional)\n\nUse a simple approach (getopt or manual parsing) to avoid adding dependencies.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-13T16:57:07.363622264-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-13T17:49:00.005416242-05:00","closed_at":"2026-01-13T17:49:00.005416242-05:00","close_reason":"CLI argument parsing implemented with --images, --camera, --output, --max-frames, --help"}
{"id":"visual_odometry-ahk","title":"Use std::span for non-owning vector parameters (4 instances)","status":"closed","priority":3,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T18:16:37.56965652-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T18:33:18.483005855-05:00","closed_at":"2026-01-12T18:33:18.483005855-05:00","close_reason":"Changed vector const\u0026 to std::span in FeatureMatcher::match and MotionEstimator::estimate"}
{"id":"visual_odometry-b8c","title":"Fix security vulnerabilities in MatchAnythingMatcher","description":"CRITICAL: Command injection via unescaped shell args (line 93), weak RNG with unseeded std::rand() for temp files (line 53), silent error swallowing (line 102). Will become moot when subprocess approach is removed, but fix if that's delayed.","status":"closed","priority":0,"issue_type":"bug","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T18:38:55.71631904-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-20T19:08:56.392049637-05:00","closed_at":"2026-01-20T19:08:56.392049637-05:00","close_reason":"Superseded: switching to LightGlue/DISK via ONNX instead of MatchAnything subprocess. See visual_odometry-siw and visual_odometry-utm."}
{"id":"visual_odometry-bak","title":"[Research] Export EfficientLoFTR to ONNX","description":"Investigate exporting EfficientLoFTR (zju3dv/efficientloftr) to ONNX format. EfficientLoFTR is 'LoFTR with sparse-like speed'. May require custom ops or architectural changes. Low priority - LightGlue likely sufficient for most VO use cases.","status":"open","priority":3,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:08:42.496696467-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-20T19:08:42.496696467-05:00"}
{"id":"visual_odometry-bdz","title":"Fix X/Y/Z time-series plots in compare_trajectories.py","description":"X, Y, Z position plots look weird but error plot looks correct. Investigate coordinate extraction or axis handling in the time-series plotting code.","status":"closed","priority":2,"issue_type":"bug","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T18:09:09.05761033-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T18:11:46.269578124-05:00","closed_at":"2026-01-25T18:11:46.269578124-05:00","close_reason":"Closed"}
{"id":"visual_odometry-bl0","title":"Convert all West const to East const (42 instances)","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T18:16:22.297600006-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T18:23:21.770410067-05:00","closed_at":"2026-01-12T18:23:21.770410067-05:00","close_reason":"Refactored to new coding standards: east const, snake_case, [[nodiscard]], trailing returns, tl::expected for error handling. All tests pass."}
{"id":"visual_odometry-bpm","title":"Test Beads integration","status":"closed","priority":3,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T11:05:41.19243688-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T11:05:48.250742983-05:00","closed_at":"2026-01-12T11:05:48.250742983-05:00","close_reason":"Test successful"}
{"id":"visual_odometry-c64","title":"Replace output parameters with return values in FeatureDetector::detect","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T18:16:30.6614809-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T18:23:38.492632459-05:00","closed_at":"2026-01-12T18:23:38.492632459-05:00","close_reason":"Completed as part of P1 refactoring - all functions now use trailing returns, member vars are snake_case, FeatureDetector::detect returns DetectionResult struct"}
{"id":"visual_odometry-c84","title":"Set up Doxygen documentation","description":"Add doxygen and graphviz dependencies, configure CMake docs target in ENABLE_DEVELOPER_MODE, create Doxyfile with project settings. Add pixi task for doc generation. Reference: chessBot2 CMakeLists.txt and pixi.toml","status":"closed","priority":3,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:09:17.500313956-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T13:42:34.332618222-05:00","closed_at":"2026-01-12T13:42:34.332618222-05:00","close_reason":"Configured in CMakeLists.txt as part of CMake setup","dependencies":[{"issue_id":"visual_odometry-c84","depends_on_id":"visual_odometry-odu","type":"blocks","created_at":"2026-01-12T12:09:56.41507373-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-c8i","title":"Create OnnxSession wrapper class","description":"Create include/visual_odometry/onnx_session.hpp with OnnxSession class. Methods: constructor takes model path, run() takes input tensors returns output tensors. Use Ort::Session internally. Follow project style (east const, [[nodiscard]], etc). SUCCESS: Header compiles without error.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:45:08.364916029-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-21T10:00:00.450700878-05:00","closed_at":"2026-01-21T10:00:00.450700878-05:00","close_reason":"Created OnnxSession wrapper class in include/visual_odometry/onnx_session.hpp and src/onnx_session.cpp. Build passes, tests pass.","dependencies":[{"issue_id":"visual_odometry-c8i","depends_on_id":"visual_odometry-ijv","type":"blocks","created_at":"2026-01-20T19:45:56.765026658-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-cez","title":"Create test trajectory generator for visualization validation","description":"Create a Python script that generates synthetic trajectories in TUM ground truth format for validating the visualization pipeline.\n\nGenerate these trajectory shapes:\n1. **Line** - straight line along X axis\n2. **Circle** - circular path in XY plane  \n3. **Rectangle** - rectangular path in XY plane\n4. **Sinewave** - sinusoidal path (X forward, Y oscillating)\n\nOutput format (TUM): `timestamp tx ty tz qx qy qz qw`\n\nScript should:\n- Output to stdout or file\n- Configurable number of poses (default 100)\n- Configurable scale/amplitude\n- Include proper quaternion orientation (facing direction of travel)\n\nUsage:\n```bash\npython scripts/generate_test_trajectory.py --shape circle --poses 100 \u003e test_circle.txt\npixi run -e viz python scripts/visualize_trajectory.py --ground-truth test_circle.txt\n```\n\nSUCCESS: All 4 shapes render correctly in viser visualization.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T16:53:49.533998262-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T17:08:00.049659256-05:00","closed_at":"2026-01-25T17:08:00.049659256-05:00","close_reason":"Implemented generate_test_trajectory.py with line, circle, rectangle, sinewave shapes"}
{"id":"visual_odometry-ckz","title":"Use std::ranges instead of iterator-based algorithms","description":"Replace iterator-based STL algorithms with C++20 ranges versions. Example: std::sort(v.begin(), v.end()) -\u003e std::ranges::sort(v). Check image_loader.cpp and other files flagged by modernize-use-ranges.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T20:31:12.484662395-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-24T01:38:01.66894252-05:00","closed_at":"2026-01-24T01:38:01.66894252-05:00","close_reason":"Fixed in commit c5f23e3","dependencies":[{"issue_id":"visual_odometry-ckz","depends_on_id":"visual_odometry-96q","type":"blocks","created_at":"2026-01-23T20:31:19.492340252-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-d1a","title":"Add trailing return types to all functions (15 instances)","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T18:16:29.709388495-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T18:23:38.507950251-05:00","closed_at":"2026-01-12T18:23:38.507950251-05:00","close_reason":"Completed as part of P1 refactoring - all functions now use trailing returns, member vars are snake_case, FeatureDetector::detect returns DetectionResult struct"}
{"id":"visual_odometry-d3j","title":"Add tests for image-trajectory timestamp matching","description":"Add unit tests for the image timestamp matching functions in plot_trajectory.py.\n\nTest cases for `match_images_to_timestamps`:\n- Exact timestamp match returns correct image\n- Closest image selected when no exact match\n- Returns None when timestamp is outside image range (beyond max_time_diff)\n- Handles empty image list\n\nTest cases for `get_image_paths_with_timestamps`:\n- Parses TUM-style timestamp filenames correctly\n- Falls back to index for non-timestamp filenames\n- Returns sorted list\n\nPut tests in scripts/tests/test_plot_trajectory.py\n\nSUCCESS: All timestamp matching edge cases handled correctly.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T17:50:28.751616598-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T17:54:46.802364328-05:00","closed_at":"2026-01-25T17:54:46.802364328-05:00","close_reason":"Added 12 tests for image-trajectory timestamp matching - all pass"}
{"id":"visual_odometry-d3l","title":"Add visualization module","description":"Visualize trajectory, matched features, and optionally point cloud reconstruction","status":"closed","priority":3,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:01:34.846086951-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T15:49:02.681294452-05:00","closed_at":"2026-01-12T15:49:02.681294452-05:00","close_reason":"Superseded by smaller incremental tasks","dependencies":[{"issue_id":"visual_odometry-d3l","depends_on_id":"visual_odometry-xi8","type":"blocks","created_at":"2026-01-12T12:02:20.118364336-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-dhi","title":"Set up SonarCloud integration","description":"Create sonar-project.properties with project key/org, source paths, C++ compile-commands path, coverage report path, and exclusions. Set up GitHub workflow (.github/workflows/sonarcloud.yml) with coverage build, gcovr XML generation, and SonarCloud scanner. Requires SONAR_TOKEN secret. Reference: /home/griswald/picknik/chessBot2/sonar-project.properties and .github/workflows/sonarcloud.yml","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:08:50.33154144-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T13:57:51.261876124-05:00","closed_at":"2026-01-12T13:57:51.261876124-05:00","close_reason":"Created .github/workflows/sonarcloud.yml and sonar-project.properties. NOTE: Update sonar.projectKey and sonar.organization, and add SONAR_TOKEN secret to GitHub.","dependencies":[{"issue_id":"visual_odometry-dhi","depends_on_id":"visual_odometry-zrb","type":"blocks","created_at":"2026-01-12T12:09:56.168697971-05:00","created_by":"Griswald Brooks"},{"issue_id":"visual_odometry-dhi","depends_on_id":"visual_odometry-0ff","type":"blocks","created_at":"2026-01-12T12:09:56.213270556-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-di7","title":"Set up pytest testing framework","description":"Configure pytest with fixtures for test images and camera parameters","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:01:41.999508071-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T12:10:25.64123506-05:00","closed_at":"2026-01-12T12:10:25.64123506-05:00","close_reason":"Superseded by Catch2 testing issue (visual_odometry-7o7) for C++ project","dependencies":[{"issue_id":"visual_odometry-di7","depends_on_id":"visual_odometry-eyx","type":"blocks","created_at":"2026-01-12T12:02:20.293952543-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-djp","title":"Add Python viz environment with viser","description":"Create scripts/requirements.txt with viser, numpy. Or add to pixi.toml as Python deps. Test viser hello world. ~15 min","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T15:56:00.711499193-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T16:27:48.994287516-05:00","closed_at":"2026-01-12T16:27:48.994287516-05:00","close_reason":"Created Python viz environment with viser in pixi.toml, test script, and trajectory visualization script."}
{"id":"visual_odometry-dyt","title":"Set up Pixi environment management","description":"Create pixi.toml with conda-forge channel, platform config, activation scripts, and task definitions (configure, build, test, coverage, format-check, tidy, docs, clean). Reference: /home/griswald/picknik/chessBot2/pixi.toml","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:08:49.959709476-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T13:30:13.200653852-05:00","closed_at":"2026-01-12T13:30:13.200653852-05:00","close_reason":"Created pixi.toml with OpenCV, Eigen, and dev tooling. Tested pixi install successfully.","dependencies":[{"issue_id":"visual_odometry-dyt","depends_on_id":"visual_odometry-m7o","type":"blocks","created_at":"2026-01-12T12:09:40.148187635-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-e0p","title":"Add file existence checks to compare_trajectories.py","description":"compare_trajectories.py will crash with unclear errors if files don't exist. Add existence checks before loading like visualize_trajectory.py does.","status":"closed","priority":2,"issue_type":"bug","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T18:09:08.825303752-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T18:11:46.280427658-05:00","closed_at":"2026-01-25T18:11:46.280427658-05:00","close_reason":"Closed"}
{"id":"visual_odometry-eqb","title":"Update all call sites to use std::visit with matcher variant","description":"Update main.cpp, benchmark_matchers.cpp, Python bindings, and tests to use std::visit when calling match_images(). Use concept-constrained lambdas where appropriate: std::visit([](matcher auto\u0026 m) { ... }, matcher).","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T16:45:50.843873732-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T16:52:46.644924349-05:00","closed_at":"2026-01-23T16:52:46.644924349-05:00","close_reason":"Closed","dependencies":[{"issue_id":"visual_odometry-eqb","depends_on_id":"visual_odometry-yvr","type":"blocks","created_at":"2026-01-23T16:46:00.214895648-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-eyx","title":"Set up Python project structure","description":"Create basic project layout with src/, tests/, and configuration files (pyproject.toml, requirements.txt)","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:01:26.042084813-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T12:10:25.429806354-05:00","closed_at":"2026-01-12T12:10:25.429806354-05:00","close_reason":"Superseded by C++ project structure issue (visual_odometry-m7o) based on chessBot2 reference"}
{"id":"visual_odometry-ftq","title":"Bind ImageMatcher classes","description":"Create nanobind bindings for ImageMatcher:\n- ImageMatcher base class (abstract)\n- OrbImageMatcher implementation\n- create_matcher(name) factory function\n- match_images(img1, img2) -\u003e MatchResult\n\nMatchResult should expose points1, points2 as numpy arrays.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-19T18:47:15.88211184-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-19T19:21:15.546870132-05:00","closed_at":"2026-01-19T19:21:15.546870132-05:00","close_reason":"ImageMatcher, OrbImageMatcher, MatchResult, and create_matcher bindings complete","dependencies":[{"issue_id":"visual_odometry-ftq","depends_on_id":"visual_odometry-l1z","type":"blocks","created_at":"2026-01-19T18:50:54.473298919-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-grr","title":"Add [[nodiscard]] to all value-returning functions (14 instances)","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T18:16:22.756248908-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T18:23:21.779208217-05:00","closed_at":"2026-01-12T18:23:21.779208217-05:00","close_reason":"Refactored to new coding standards: east const, snake_case, [[nodiscard]], trailing returns, tl::expected for error handling. All tests pass."}
{"id":"visual_odometry-i0g","title":"Output trajectory to JSON file","description":"Write camera poses (R, t) to a JSON file that Python can read. Simple format: list of {rotation: [], translation: []} objects. ~20 min","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T15:49:33.005032552-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T19:40:03.359291461-05:00","closed_at":"2026-01-12T19:40:03.359291461-05:00","close_reason":"Added to_json() and save_to_json() methods to Trajectory class. JSON format includes rotation matrices and translation vectors.","dependencies":[{"issue_id":"visual_odometry-i0g","depends_on_id":"visual_odometry-m46","type":"blocks","created_at":"2026-01-12T15:49:49.271608782-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-ijv","title":"Add onnxruntime to CMakeLists.txt","description":"Add find_package(onnxruntime) or equivalent to CMakeLists.txt. Link onnxruntime to visual_odometry library. SUCCESS: pixi run build completes and links against onnxruntime.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:45:08.213475762-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-21T09:58:13.449100391-05:00","closed_at":"2026-01-21T09:58:13.449100391-05:00","close_reason":"Added onnxruntime detection and linking to CMakeLists.txt, build passes, tests pass","dependencies":[{"issue_id":"visual_odometry-ijv","depends_on_id":"visual_odometry-jbv","type":"blocks","created_at":"2026-01-20T19:45:56.633720262-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-j9o","title":"Load camera intrinsics in main.cpp","description":"Use CameraIntrinsics::load_from_yaml() to load camera parameters.\nHandle errors gracefully with clear error messages.\nExit with non-zero status on failure.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-13T16:57:07.624546706-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-13T18:43:04.423172816-05:00","closed_at":"2026-01-13T18:43:04.423172816-05:00","close_reason":"Camera intrinsics loading implemented with error handling","dependencies":[{"issue_id":"visual_odometry-j9o","depends_on_id":"visual_odometry-acx","type":"blocks","created_at":"2026-01-13T16:57:15.308543147-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-jbv","title":"Add onnxruntime dependency to pixi.toml","description":"Add onnxruntime-cpp (or onnxruntime) to pixi.toml dependencies. SUCCESS: pixi install completes without error and onnxruntime headers are available.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:45:08.049967442-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-21T09:57:00.967936242-05:00","closed_at":"2026-01-21T09:57:00.967936242-05:00","close_reason":"onnxruntime-cpp added to pixi.toml, pixi install completed, headers available at include/onnxruntime/"}
{"id":"visual_odometry-jsr","title":"Integrate onnxruntime in C++ for learned matcher inference","description":"Add onnxruntime to C++ build and create OnnxImageMatcher class that loads the exported ONNX model and runs inference. Should handle: model loading, image preprocessing (match HF processor), inference session management, output postprocessing to MatchResult.","status":"closed","priority":1,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T18:38:55.115750182-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-20T19:08:56.369576982-05:00","closed_at":"2026-01-20T19:08:56.369576982-05:00","close_reason":"Superseded: switching to LightGlue/DISK via ONNX instead of MatchAnything subprocess. See visual_odometry-siw and visual_odometry-utm.","dependencies":[{"issue_id":"visual_odometry-jsr","depends_on_id":"visual_odometry-3kk","type":"blocks","created_at":"2026-01-20T18:39:19.964668292-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-kaw","title":"Remove match_anything.py","status":"open","priority":3,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T18:04:08.882509064-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T18:04:08.882509064-05:00"}
{"id":"visual_odometry-kp7","title":"Refactor FeatureMatcher from class to pure function","description":"Refactor FeatureMatcher from class to pure function + config struct. Create: struct FeatureMatcherConfig { float ratio_threshold = 0.75f; }; and [[nodiscard]] auto match_features(..., FeatureMatcherConfig const\u0026) -\u003e MatchResult; Keep class as thin wrapper if needed. SUCCESS: pixi run build \u0026\u0026 pixi run test passes.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T18:38:55.428387709-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T13:28:35.373647783-05:00","closed_at":"2026-01-23T13:28:35.373647783-05:00","close_reason":"Closed"}
{"id":"visual_odometry-l1z","title":"Add nanobind and cvnp_nano to CMake","description":"Add nanobind and cvnp_nano dependencies to CMakeLists.txt.\n\n- nanobind: Python bindings library (faster/smaller than pybind11)\n- cvnp_nano: cv::Mat \u003c-\u003e numpy conversion with shared memory\n\nUse FetchContent or git submodules. Configure Python module target.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-19T18:47:14.828563404-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-19T19:03:23.578536337-05:00","closed_at":"2026-01-19T19:03:23.578536337-05:00","close_reason":"CMake configured with nanobind and cvnp_nano. Module builds and imports successfully."}
{"id":"visual_odometry-l5t","title":"Bind MotionEstimator and CameraIntrinsics","description":"Create nanobind bindings for:\n- CameraIntrinsics struct (fx, fy, cx, cy)\n- CameraIntrinsics.load_from_yaml(path)\n- MotionEstimator(intrinsics)\n- estimate(points1, points2) -\u003e MotionEstimate\n\nMotionEstimate should expose rotation/translation as numpy arrays (Eigen -\u003e numpy is built-in to nanobind).","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-19T18:47:16.386905047-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-19T19:25:27.686597003-05:00","closed_at":"2026-01-19T19:25:27.686597003-05:00","close_reason":"CameraIntrinsics, MotionEstimate, and MotionEstimator bindings complete","dependencies":[{"issue_id":"visual_odometry-l5t","depends_on_id":"visual_odometry-l1z","type":"blocks","created_at":"2026-01-19T18:50:54.524884963-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-lt4","title":"Load and display image pair with OpenCV","description":"Create a simple test that loads two sequential images and displays them. Validates OpenCV integration works. ~15 min","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T15:49:19.565332549-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T16:29:38.068349035-05:00","closed_at":"2026-01-12T16:29:38.068349035-05:00","close_reason":"Created ImageLoader class with tests. Loads image pairs from directory, supports iteration. All 8 tests pass."}
{"id":"visual_odometry-lyl","title":"Write trajectory JSON output in main.cpp","description":"After processing loop completes:\n1. Use Trajectory::to_json() to serialize\n2. Write to output file path\n3. Report success with frame count and output path","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-13T16:57:08.476811259-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-13T19:31:29.164283625-05:00","closed_at":"2026-01-13T19:31:29.164283625-05:00","close_reason":"Trajectory JSON output using save_to_json()","dependencies":[{"issue_id":"visual_odometry-lyl","depends_on_id":"visual_odometry-ze5","type":"blocks","created_at":"2026-01-13T16:57:15.593354908-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-m0d","title":"Detect ORB keypoints on single image","description":"Detect ORB features on one image, draw keypoints, display result. First real CV code. ~15 min","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T15:49:20.295578442-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T16:31:37.102485239-05:00","closed_at":"2026-01-12T16:31:37.102485239-05:00","close_reason":"Created FeatureDetector class with ORB detection and drawing. All 6 new tests pass (14 total).","dependencies":[{"issue_id":"visual_odometry-m0d","depends_on_id":"visual_odometry-lt4","type":"blocks","created_at":"2026-01-12T15:49:46.688189515-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-m46","title":"Compute Essential matrix and recover pose","description":"Use findEssentialMat() with RANSAC on matched points. Call recoverPose() to get R, t. Print results. Use hardcoded camera intrinsics for now. ~30 min","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T15:49:21.605254366-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T16:37:03.473532213-05:00","closed_at":"2026-01-12T16:37:03.473532213-05:00","close_reason":"Created MotionEstimator with Essential matrix and pose recovery. 5 new tests pass (24 total).","dependencies":[{"issue_id":"visual_odometry-m46","depends_on_id":"visual_odometry-3l0","type":"blocks","created_at":"2026-01-12T15:49:48.446564378-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-m7o","title":"Create project directory structure","description":"Create src/, include/visual_odometry/, tests/, docs/ directories following chessBot2 structure. Reference: /home/griswald/picknik/chessBot2/ layout","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:09:27.809945165-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T12:21:46.043836775-05:00","closed_at":"2026-01-12T12:21:46.043836775-05:00","close_reason":"Created src/, include/visual_odometry/, tests/, docs/ directories with .gitkeep files"}
{"id":"visual_odometry-mq3","title":"Download KITTI sample sequence","description":"Download a small KITTI odometry sequence (e.g., sequence 00, first 100 frames) for testing. Document camera intrinsics. ~15 min","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T15:49:34.519438906-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T16:26:21.966443076-05:00","closed_at":"2026-01-12T16:26:21.966443076-05:00","close_reason":"Created data directory, KITTI camera intrinsics, download script, and downloaded ground truth poses. Images require manual download from KITTI website."}
{"id":"visual_odometry-mr0","title":"Implement feature detection module","description":"Implement feature detection using ORB/SIFT/FAST detectors for keypoint extraction from frames","status":"closed","priority":2,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:01:26.395777119-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T15:49:02.636584245-05:00","closed_at":"2026-01-12T15:49:02.636584245-05:00","close_reason":"Superseded by smaller incremental tasks","dependencies":[{"issue_id":"visual_odometry-mr0","depends_on_id":"visual_odometry-eyx","type":"blocks","created_at":"2026-01-12T12:02:13.280728831-05:00","created_by":"Griswald Brooks"},{"issue_id":"visual_odometry-mr0","depends_on_id":"visual_odometry-yw3","type":"blocks","created_at":"2026-01-12T12:02:13.321268458-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-n78","title":"Add CLI interface","description":"Create command-line interface for running VO on video files or image sequences","status":"closed","priority":3,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:01:42.176172932-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T15:49:02.685758922-05:00","closed_at":"2026-01-12T15:49:02.685758922-05:00","close_reason":"Superseded by smaller incremental tasks","dependencies":[{"issue_id":"visual_odometry-n78","depends_on_id":"visual_odometry-xi8","type":"blocks","created_at":"2026-01-12T12:02:20.50303079-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-n90","title":"Auto-align estimated trajectory to ground truth","description":"Add a button to automatically find optimal scale and offset that aligns estimated trajectory to ground truth.\n\n**Implementation:** Umeyama alignment (standard for monocular VO evaluation)\n- Closed-form solution for similarity transform (scale + rotation + translation)\n- Python backend using numpy/scipy\n- Compute alignment when generating HTML, embed optimal values\n- 'Auto-align' button in HTML applies pre-computed optimal scale/offsets to sliders\n\nReference: S. Umeyama, 'Least-Squares Estimation of Transformation Parameters Between Two Point Patterns', IEEE TPAMI 1991","status":"closed","priority":2,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T19:29:16.159995064-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T19:46:49.705214852-05:00","closed_at":"2026-01-25T19:46:49.705214852-05:00","close_reason":"Closed"}
{"id":"visual_odometry-nlo","title":"Create benchmark comparison script","description":"Create scripts/compare_matchers.py that runs benchmark with ORB and LightGlue, loads JSON results, prints markdown table comparing speed and accuracy. SUCCESS: python scripts/compare_matchers.py outputs comparison table.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:45:34.483206033-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T13:57:56.157076674-05:00","closed_at":"2026-01-23T13:57:56.157076674-05:00","close_reason":"Closed","dependencies":[{"issue_id":"visual_odometry-nlo","depends_on_id":"visual_odometry-5hk","type":"blocks","created_at":"2026-01-20T19:45:58.295433761-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-nws","title":"Add pre-commit CI workflow","description":"Create .github/workflows/pre-commit.yml with format-check job (clang-format --dry-run --Werror) and clang-tidy job for static analysis on PRs. Reference: /home/griswald/picknik/chessBot2/.github/workflows/pre-commit.yml","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:09:02.468026789-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T13:55:09.567616409-05:00","closed_at":"2026-01-12T13:55:09.567616409-05:00","close_reason":"Created .github/workflows/pre-commit.yml with format-check and clang-tidy jobs","dependencies":[{"issue_id":"visual_odometry-nws","depends_on_id":"visual_odometry-6ok","type":"blocks","created_at":"2026-01-12T12:09:55.895309119-05:00","created_by":"Griswald Brooks"},{"issue_id":"visual_odometry-nws","depends_on_id":"visual_odometry-q7e","type":"blocks","created_at":"2026-01-12T12:09:55.977133946-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-odu","title":"Configure CMake build system with presets","description":"Create CMakeLists.txt with C++20, compiler warnings, options for testing/coverage/sanitizers/clang-tidy. Add CMakePresets.json with dev, coverage, release, and ci presets. Reference: /home/griswald/picknik/chessBot2/CMakeLists.txt and CMakePresets.json","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:08:50.161526084-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T13:42:02.60277196-05:00","closed_at":"2026-01-12T13:42:02.60277196-05:00","close_reason":"Created CMakeLists.txt, CMakePresets.json, tests/CMakeLists.txt. Build and tests pass.","dependencies":[{"issue_id":"visual_odometry-odu","depends_on_id":"visual_odometry-dyt","type":"blocks","created_at":"2026-01-12T12:09:40.343736566-05:00","created_by":"Griswald Brooks"},{"issue_id":"visual_odometry-odu","depends_on_id":"visual_odometry-m7o","type":"blocks","created_at":"2026-01-12T12:09:40.412019347-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-plk","title":"Rename camelCase member variables to snake_case (6 vars)","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T18:16:30.18572167-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T18:23:38.500110557-05:00","closed_at":"2026-01-12T18:23:38.500110557-05:00","close_reason":"Completed as part of P1 refactoring - all functions now use trailing returns, member vars are snake_case, FeatureDetector::detect returns DetectionResult struct"}
{"id":"visual_odometry-pn8","title":"Configure AddressSanitizer and UBSan","description":"Add CMake ENABLE_SANITIZERS option for ASan+UBSan, configure CI job with ASAN_OPTIONS and UBSAN_OPTIONS env vars (detect_leaks, detect_stack_use_after_return, print_stacktrace, halt_on_error). Reference: chessBot2 CMakeLists.txt and ci.yml sanitizers job","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:09:17.324162371-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T13:42:34.322307434-05:00","closed_at":"2026-01-12T13:42:34.322307434-05:00","close_reason":"Configured in CMakeLists.txt as part of CMake setup","dependencies":[{"issue_id":"visual_odometry-pn8","depends_on_id":"visual_odometry-odu","type":"blocks","created_at":"2026-01-12T12:09:48.714042017-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-q0k","title":"Implement LightGlue output postprocessing","description":"Parse ONNX output tensors into MatchResult struct. Extract matched keypoint coordinates, convert to cv::Point2f vectors. Handle coordinate scaling back to original image size. SUCCESS: match_images() returns populated MatchResult with points1/points2.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:45:25.749875108-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T12:50:52.648492286-05:00","closed_at":"2026-01-23T12:50:52.648492286-05:00","close_reason":"Closed","dependencies":[{"issue_id":"visual_odometry-q0k","depends_on_id":"visual_odometry-rqg","type":"blocks","created_at":"2026-01-20T19:45:57.490462233-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-q11","title":"Add tests for generate_test_trajectory.py","description":"Add unit tests for the trajectory generation functions.\n\nTest cases:\n- `generate_line`: verify X increases linearly, Y and Z are zero\n- `generate_circle`: verify points lie on circle (constant radius from center)\n- `generate_rectangle`: verify points form rectangular path\n- `generate_sinewave`: verify X increases, Y follows sine pattern\n- `direction_to_quaternion`: verify quaternion points in expected direction\n\nPut tests in scripts/tests/test_generate_trajectory.py\n\nSUCCESS: All trajectory shapes generate geometrically correct paths.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T17:50:12.284995969-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T17:53:24.470296937-05:00","closed_at":"2026-01-25T17:53:24.470296937-05:00","close_reason":"Added 20 tests covering all trajectory shapes and direction_to_quaternion - all pass"}
{"id":"visual_odometry-q7e","title":"Configure clang-tidy static analysis","description":"Create .clang-tidy with bugprone, clang-analyzer, cppcoreguidelines, modernize, performance, portability, readability checks. Define naming conventions (CamelCase classes, camelBack functions, UPPER_CASE constants). Reference: /home/griswald/picknik/chessBot2/.clang-tidy","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:09:02.827937631-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T13:47:37.298803656-05:00","closed_at":"2026-01-12T13:47:37.298803656-05:00","close_reason":"Created .clang-tidy based on chessBot2 config","dependencies":[{"issue_id":"visual_odometry-q7e","depends_on_id":"visual_odometry-odu","type":"blocks","created_at":"2026-01-12T12:09:40.804137716-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-qr4","title":"Refactor orb_matcher to satisfy matcher concept","description":"Refactor OrbImageMatcher to orb_matcher (snake_case). Remove inheritance from ImageMatcher base class. Ensure it satisfies the matcher concept. Keep the thin wrapper that delegates to match_images_orb() pure function.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T16:45:50.424626119-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T16:48:29.672292837-05:00","closed_at":"2026-01-23T16:48:29.672292837-05:00","close_reason":"Closed","dependencies":[{"issue_id":"visual_odometry-qr4","depends_on_id":"visual_odometry-5rh","type":"blocks","created_at":"2026-01-23T16:45:59.807544968-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-rai","title":"Replace exceptions with tl::expected error handling","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T18:16:23.600426619-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T18:23:21.792088495-05:00","closed_at":"2026-01-12T18:23:21.792088495-05:00","close_reason":"Refactored to new coding standards: east const, snake_case, [[nodiscard]], trailing returns, tl::expected for error handling. All tests pass."}
{"id":"visual_odometry-rbs","title":"Refactor FeatureDetector from class to pure function","description":"Refactor FeatureDetector from class to pure function + config struct. Create: struct FeatureDetectorConfig { int max_features = 2000; }; and [[nodiscard]] auto detect_features(cv::Mat const\u0026 image, FeatureDetectorConfig const\u0026 config) -\u003e DetectionResult; Keep class as thin wrapper if needed for Python bindings. SUCCESS: pixi run build \u0026\u0026 pixi run test passes, existing tests unchanged.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T18:38:55.264029043-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T13:27:02.130594444-05:00","closed_at":"2026-01-23T13:27:02.130594444-05:00","close_reason":"Closed"}
{"id":"visual_odometry-rqg","title":"Implement LightGlue ONNX inference","description":"In LightGlueImageMatcher::match_images(), call OnnxSession::run() with preprocessed images. Get output tensors (keypoints0, keypoints1, matches). SUCCESS: Inference runs without crash on two test images.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:45:25.576546914-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T12:50:35.450721399-05:00","closed_at":"2026-01-23T12:50:35.450721399-05:00","close_reason":"Closed","dependencies":[{"issue_id":"visual_odometry-rqg","depends_on_id":"visual_odometry-5nl","type":"blocks","created_at":"2026-01-20T19:45:57.295245505-05:00","created_by":"Griswald Brooks"},{"issue_id":"visual_odometry-rqg","depends_on_id":"visual_odometry-3ts","type":"blocks","created_at":"2026-01-20T19:45:57.344285304-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-rtf","title":"Use .value() and .has_value() instead of * for tl::expected","description":"Coding standard: When working with tl::expected, always use explicit .value() and .has_value() methods instead of the * dereference operator. This improves code clarity and makes error handling intent explicit.\n\nExample:\n```cpp\n// CORRECT\nif (result.has_value()) {\n    auto const\u0026 data = result.value();\n}\n\n// WRONG - avoid * operator\nif (result) {\n    auto const\u0026 data = *result;\n}\n```\n\nUpdate .claude/claude.md and agent files to document this convention.","status":"open","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T16:14:13.56486031-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T16:14:13.56486031-05:00"}
{"id":"visual_odometry-s0f","title":"Fix KITTI aspect ratio in compare_trajectories.py","description":"compare_trajectories.py uses 4/3 aspect ratio (line 69) but should use 1241/376 (~3.3) to match KITTI camera and visualize_trajectory.py","status":"closed","priority":2,"issue_type":"bug","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T18:09:08.703585007-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T18:11:46.274750416-05:00","closed_at":"2026-01-25T18:11:46.274750416-05:00","close_reason":"Closed"}
{"id":"visual_odometry-s1u","title":"Remove deprecated ImageMatcher classes","description":"Remove the deprecated ImageMatcher, OrbImageMatcher, and LightGlueImageMatcher classes entirely. Update Python bindings to only expose the new snake_case types (orb_matcher, lightglue_matcher) and the variant-based API.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T17:22:53.884046663-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T18:33:13.375314036-05:00","closed_at":"2026-01-23T18:33:13.375314036-05:00","close_reason":"Closed"}
{"id":"visual_odometry-sd1","title":"Add LightGlue integration test","description":"Create tests/test_lightglue_matcher.cpp. Test: load model, match two similar images, verify non-empty matches. Test: verify points1.size() == points2.size(). Skip test if model file not found. SUCCESS: pixi run test passes (or skips gracefully if no model).","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:45:25.911230921-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T12:53:32.505814603-05:00","closed_at":"2026-01-23T12:53:32.505814603-05:00","close_reason":"Closed","dependencies":[{"issue_id":"visual_odometry-sd1","depends_on_id":"visual_odometry-q0k","type":"blocks","created_at":"2026-01-20T19:45:57.61150745-05:00","created_by":"Griswald Brooks"},{"issue_id":"visual_odometry-sd1","depends_on_id":"visual_odometry-9yl","type":"blocks","created_at":"2026-01-20T19:45:57.663141611-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-siw","title":"Integrate onnxruntime into C++ build","description":"Add onnxruntime as dependency via pixi/CMake. Create OnnxInferenceSession wrapper class for loading and running ONNX models. This is prerequisite for all learned matchers (LightGlue, DISK, SuperPoint, etc.).","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:08:41.892021667-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-20T19:44:56.697933855-05:00","closed_at":"2026-01-20T19:44:56.697933855-05:00","close_reason":"Breaking down into smaller Ralph-ready tasks"}
{"id":"visual_odometry-sti","title":"Remove subprocess/temp file approach from MatchAnythingMatcher","description":"Current MatchAnythingMatcher spawns subprocess + writes temp files for EVERY frame pair. Model reloads each call (~500ms overhead). Replace with either: 1) ONNX inference (preferred), or 2) Embedded Python via nanobind. Delete all temp file and popen logic.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T18:38:55.583098643-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-20T19:08:56.380747228-05:00","closed_at":"2026-01-20T19:08:56.380747228-05:00","close_reason":"Superseded: switching to LightGlue/DISK via ONNX instead of MatchAnything subprocess. See visual_odometry-siw and visual_odometry-utm.","dependencies":[{"issue_id":"visual_odometry-sti","depends_on_id":"visual_odometry-jsr","type":"blocks","created_at":"2026-01-20T18:39:20.055155828-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-u89","title":"Configure .gitignore for C++ project","description":"Add comprehensive .gitignore for build artifacts, compiled objects, CMake files, coverage data, IDE files, Doxygen output, pixi env, clang cache, SonarCloud working dirs. Reference: /home/griswald/picknik/chessBot2/.gitignore","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:09:17.683222946-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T13:48:31.552600949-05:00","closed_at":"2026-01-12T13:48:31.552600949-05:00","close_reason":"Created .gitignore based on chessBot2 config"}
{"id":"visual_odometry-ue2","title":"Add --matcher lightglue CLI support","description":"Update main.cpp to accept --matcher lightglue. Pass model path (default: models/disk_lightglue_fused.onnx). Print matcher name on startup. SUCCESS: ./visual_odometry --images test_data --matcher lightglue runs without error.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:45:26.064406523-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T12:55:50.994700792-05:00","closed_at":"2026-01-23T12:55:50.994700792-05:00","close_reason":"Closed","dependencies":[{"issue_id":"visual_odometry-ue2","depends_on_id":"visual_odometry-q0k","type":"blocks","created_at":"2026-01-20T19:45:57.838688565-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-uec","title":"Add camera calibration support","description":"Support loading camera intrinsic parameters from file or calibrating from checkerboard images","status":"closed","priority":2,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:01:34.50715434-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T15:49:02.676350435-05:00","closed_at":"2026-01-12T15:49:02.676350435-05:00","close_reason":"Superseded by smaller incremental tasks","dependencies":[{"issue_id":"visual_odometry-uec","depends_on_id":"visual_odometry-eyx","type":"blocks","created_at":"2026-01-12T12:02:19.879767814-05:00","created_by":"Griswald Brooks"},{"issue_id":"visual_odometry-uec","depends_on_id":"visual_odometry-yw3","type":"blocks","created_at":"2026-01-12T12:02:19.931021733-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-utm","title":"Add LightGlue matcher via ONNX","description":"Download LightGlue ONNX weights (fused with SuperPoint or DISK) from fabio-sim/LightGlue-ONNX releases. Create LightGlueImageMatcher : public ImageMatcher that runs end-to-end ONNX inference. Reference: github.com/OroChippw/LightGlue-OnnxRunner for C++ implementation.","status":"closed","priority":1,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:08:42.36134596-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-20T19:44:56.839203031-05:00","closed_at":"2026-01-20T19:44:56.839203031-05:00","close_reason":"Breaking down into smaller Ralph-ready tasks","dependencies":[{"issue_id":"visual_odometry-utm","depends_on_id":"visual_odometry-siw","type":"blocks","created_at":"2026-01-20T19:08:49.705569135-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-uzf","title":"Fix redundant member initializers (use-default-member-init)","description":"Remove redundant constructor initializers where default member initialization already provides the value. If member has int x_{0}, don't also initialize in constructor initializer list.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T20:31:12.928266021-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-24T01:38:01.676978718-05:00","closed_at":"2026-01-24T01:38:01.676978718-05:00","close_reason":"Fixed in commit c5f23e3","dependencies":[{"issue_id":"visual_odometry-uzf","depends_on_id":"visual_odometry-96q","type":"blocks","created_at":"2026-01-23T20:31:19.666462942-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-wb8","title":"Add BDD comments to all test files (5 files)","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T18:16:31.127419995-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T19:42:27.947910262-05:00","closed_at":"2026-01-12T19:42:27.947910262-05:00","close_reason":"Added BDD comments (GIVEN/WHEN/THEN) to all 6 test files: 117 total comment annotations"}
{"id":"visual_odometry-x8y","title":"Add Python coverage to pixi.toml","description":"Configure Python test coverage metrics using pytest-cov.\n\nSteps:\n1. Add pytest and pytest-cov to viz environment dependencies\n2. Add pixi task: `py-coverage` that runs pytest with coverage\n3. Generate HTML coverage report\n\nExample task:\n```toml\n[tasks]\npy-test = \"pytest scripts/tests/ -v\"\npy-coverage = \"pytest scripts/tests/ --cov=scripts --cov-report=html --cov-report=term\"\n```\n\nSUCCESS: `pixi run py-coverage` shows coverage percentage and generates HTML report.","status":"open","priority":3,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T17:50:28.930173565-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T17:50:28.930173565-05:00"}
{"id":"visual_odometry-xhj","title":"Create benchmark runner infrastructure","description":"Create benchmarks/benchmark_matchers.cpp with main(). Accept --matcher, --images, --output args. Time match_images() calls, compute avg ms/pair. Output results to JSON. SUCCESS: pixi run build creates benchmark_matchers executable.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-20T19:45:34.201293916-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T13:53:27.462579215-05:00","closed_at":"2026-01-23T13:53:27.462579215-05:00","close_reason":"Closed","dependencies":[{"issue_id":"visual_odometry-xhj","depends_on_id":"visual_odometry-ue2","type":"blocks","created_at":"2026-01-20T19:45:57.987659133-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-xi8","title":"Implement trajectory tracking","description":"Track cumulative camera pose over time by chaining relative transforms between frames","status":"closed","priority":2,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:01:34.668667111-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T15:49:02.671587536-05:00","closed_at":"2026-01-12T15:49:02.671587536-05:00","close_reason":"Superseded by smaller incremental tasks","dependencies":[{"issue_id":"visual_odometry-xi8","depends_on_id":"visual_odometry-1u3","type":"blocks","created_at":"2026-01-12T12:02:13.822568159-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-xo5","title":"Implement time-matched trajectory error metrics (ATE/RPE)","description":"Implement proper time-matched error computation between two trajectories.\n\nUnlike sample-matched error (which assumes frame i corresponds to frame i), time-matched error:\n1. Takes timestamps from one trajectory\n2. Interpolates the other trajectory at those timestamps\n3. Computes error at matching times\n\nMetrics to implement:\n- **ATE** (Absolute Trajectory Error): Position error at each timestamp\n- **RPE** (Relative Pose Error): Error in relative motion between timestamps\n- Per-axis errors (X, Y, Z separately)\n\nOutput:\n```python\n@dataclass\nclass TrajectoryErrorResult:\n    timestamps: np.ndarray\n    position_errors: np.ndarray  # (N, 3) per-axis\n    total_errors: np.ndarray     # (N,) euclidean\n    ate_rmse: float\n    ate_mean: float\n    rpe_rmse: float  # if computed\n```\n\nSUCCESS: Computes correct time-aligned errors even when trajectories have different sample rates.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T17:02:56.696110348-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T17:08:00.184671924-05:00","closed_at":"2026-01-25T17:08:00.184671924-05:00","close_reason":"Implemented compute_trajectory_error() with time-matched ATE metrics","dependencies":[{"issue_id":"visual_odometry-xo5","depends_on_id":"visual_odometry-0qj","type":"blocks","created_at":"2026-01-25T17:03:01.742977416-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-ymv","title":"Integrate Google Benchmark for microbenchmarking","description":"Add Google Benchmark library to the project for precise microbenchmarking of individual functions. This will complement the existing benchmark_matchers tool which measures end-to-end timing. Google Benchmark provides: statistical analysis, CPU cycle counting, parameterized benchmarks, and comparison baselines. Add to pixi.toml and CMakeLists.txt.","status":"open","priority":2,"issue_type":"feature","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T15:20:18.433177728-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T15:20:29.105885871-05:00"}
{"id":"visual_odometry-yvr","title":"Create image_matcher variant type alias","description":"Replace the ImageMatcher abstract base class with: using image_matcher = std::variant\u003corb_matcher, lightglue_matcher\u003e. Add static_asserts to verify all alternatives satisfy the matcher concept. Update create_matcher() factory to return the variant.","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T16:45:50.699853391-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T16:51:26.08388317-05:00","closed_at":"2026-01-23T16:51:26.08388317-05:00","close_reason":"Closed","dependencies":[{"issue_id":"visual_odometry-yvr","depends_on_id":"visual_odometry-qr4","type":"blocks","created_at":"2026-01-23T16:46:00.031416978-05:00","created_by":"Griswald Brooks"},{"issue_id":"visual_odometry-yvr","depends_on_id":"visual_odometry-2ew","type":"blocks","created_at":"2026-01-23T16:46:00.074577593-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-yw3","title":"Add core dependencies","description":"Add OpenCV, Eigen, and other C++ dependencies via pixi.toml for visual odometry (update from Python to C++ based on chessBot2 reference)","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:01:26.209026566-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T13:30:29.207869349-05:00","closed_at":"2026-01-12T13:30:29.207869349-05:00","close_reason":"Core dependencies (OpenCV, Eigen) added in pixi.toml"}
{"id":"visual_odometry-yyq","title":"Add edge case handling for single-frame trajectories","description":"compare_trajectories.py assumes trajectories have multiple points. Add check for len(positions) \u003c 2 before drawing splines to avoid crashes on single-frame data.","status":"closed","priority":3,"issue_type":"bug","owner":"griswald.brooks@gmail.com","created_at":"2026-01-25T18:09:08.941105917-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-25T18:11:46.285984631-05:00","closed_at":"2026-01-25T18:11:46.285984631-05:00","close_reason":"Closed"}
{"id":"visual_odometry-zd3","title":"Add Google Benchmark microbenchmarks for FeatureMatcher","description":"Create microbenchmarks for FeatureMatcher using Google Benchmark. Benchmark: match_features() with various descriptor counts and ratio thresholds. Measure BFMatcher creation overhead. Compare pure function vs class wrapper performance.","status":"open","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-23T15:20:18.719486542-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-23T15:20:29.428813675-05:00","dependencies":[{"issue_id":"visual_odometry-zd3","depends_on_id":"visual_odometry-ymv","type":"blocks","created_at":"2026-01-23T15:20:33.700026369-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-ze5","title":"Implement VO processing loop in main.cpp","description":"Main processing loop that:\n1. Load consecutive image pairs using next_pair()\n2. Detect ORB features in both images\n3. Match features between frames\n4. Estimate motion using essential matrix + RANSAC\n5. Accumulate pose in Trajectory\n6. Print progress (frame N/M, inliers, etc.)\n\nContinue until no more image pairs or max-frames reached.","status":"closed","priority":1,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-13T16:57:08.172278874-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-13T19:31:29.097626683-05:00","closed_at":"2026-01-13T19:31:29.097626683-05:00","close_reason":"Processing loop implemented: detectmatchestimateaccumulate with progress output","dependencies":[{"issue_id":"visual_odometry-ze5","depends_on_id":"visual_odometry-j9o","type":"blocks","created_at":"2026-01-13T16:57:15.443595034-05:00","created_by":"Griswald Brooks"},{"issue_id":"visual_odometry-ze5","depends_on_id":"visual_odometry-227","type":"blocks","created_at":"2026-01-13T16:57:15.517430268-05:00","created_by":"Griswald Brooks"}]}
{"id":"visual_odometry-zrb","title":"Configure code coverage with gcovr","description":"Add gcovr and llvm-tools dependencies, configure CMake ENABLE_COVERAGE option with compiler flags, generate SonarQube XML coverage reports. Exclude main.cpp and tests from coverage metrics. Reference: chessBot2 CMakeLists.txt coverage section","status":"closed","priority":2,"issue_type":"task","owner":"griswald.brooks@gmail.com","created_at":"2026-01-12T12:09:17.130090604-05:00","created_by":"Griswald Brooks","updated_at":"2026-01-12T13:42:34.328276883-05:00","closed_at":"2026-01-12T13:42:34.328276883-05:00","close_reason":"Configured in CMakeLists.txt as part of CMake setup","dependencies":[{"issue_id":"visual_odometry-zrb","depends_on_id":"visual_odometry-odu","type":"blocks","created_at":"2026-01-12T12:09:48.44037388-05:00","created_by":"Griswald Brooks"},{"issue_id":"visual_odometry-zrb","depends_on_id":"visual_odometry-7o7","type":"blocks","created_at":"2026-01-12T12:09:48.503328474-05:00","created_by":"Griswald Brooks"}]}
